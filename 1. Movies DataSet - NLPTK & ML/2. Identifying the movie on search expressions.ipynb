{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325a33f2",
   "metadata": {},
   "source": [
    "## Tf–idf: Term Frequency – Inverse Document Frequency)\n",
    "\n",
    "This method is a statistical process that evaluates how relevant a word is to a document in a collection of documents.\n",
    "\n",
    "It's mainly used on automated text analysis and for scoring words in machine learning algorithms for Natural Language Processing.\n",
    "\n",
    "This method searches each word across each document that is provided, and it counts the number of times that word appears on each document. Words that are very common across all documents observed will be off-set since they don't transmit any major insight for a specific document (or, it, is, the, a), although words that appear very frequently on a document but are not very common across all documents will have an higher score.\n",
    " - For the example of *An Interview with the Vampire* **Lestat** is a word that appears many times but won't probably be that common on other movie plots) \n",
    " \n",
    ".\n",
    "Wrapping-up, if a word appears many times in a document, but won't appear many times on other documents then probably it will be relevant, and the opposite will indicate that the word is probably not very relevant\n",
    "\n",
    ".\n",
    "*For more info:* https://monkeylearn.com/blog/what-is-tf-idf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e94394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk\n",
    "import nltk\n",
    "\n",
    "# import json to read the data file\n",
    "import json\n",
    "\n",
    "# Import scikitlearn\n",
    "import sklearn\n",
    "\n",
    "# The usual suspects\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a264e66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download both punkt and stopwords so that our script understants both punctuation and common stop-words\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd4778",
   "metadata": {},
   "source": [
    "### Data import and Preparation \n",
    "The base dataset corresponds to the movies.json file, which contain information regarding 7113 movies, containing several information about each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18b022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the movies variable that only retrieves data when called\n",
    "with open(\"movies.json\", 'r') as f:\n",
    "    movies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd460f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists of the available plots\n",
    "plots = [movie.get(\"plot\") for movie in movies]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ef269",
   "metadata": {},
   "source": [
    "### Training the model based on the English Stopwords\n",
    " - Create a vectorizer that takes int consideration the English Stopwords\n",
    " - Train the model with the plots data\n",
    " - Transform the data into a matrix like structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0c2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the vectorizer based on the English Stopwords\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(stop_words = nltk.corpus.stopwords.words(\"English\"))\n",
    "\n",
    "# Train the model with the plots information and based on the defined stopwords\n",
    "trained_vectorizer = vectorizer.fit(plots)\n",
    "\n",
    "# Transform to a document-term matrix\n",
    "tfidf = trained_vectorizer.transform(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6cf2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7113, 65108)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7856d",
   "metadata": {},
   "source": [
    "### Using Cosine Similarity\n",
    "\n",
    "Using the Cosine Similarity it's possible to compare how two matrixes are related with one another, by evaluating to what two vectors are point to, and verify how simmilar they are.\n",
    "\n",
    " - Using a new plot, that is a string that has the information regarding part of the plot of a movie we can then create a tool that helps predict which are the main films of our database that are more similar to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226efd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the initial part of the \"Interview with the Vampire\" for test\n",
    "new_plot = [\"In modern-day San Francisco, reporter Daniel Molloy interviews Louis de Pointe du Lac, who claims to be a vampire. Louis describes his human life as a wealthy plantation owner in 1791 Louisiana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43618a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 65108)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_new = trained_vectorizer.transform(new_plot) #vamos transformar os novos dados no modelo que acabámos de treinar\n",
    "tfidf_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62bd1298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview with the Vampire\n",
      "The 9th Life of Louis Drax\n",
      "Route Irish\n",
      "The Man in the Iron Mask\n",
      "Kangaroo Jack\n",
      "The Extra Man\n",
      "Daughter of Darkness\n",
      "Foxcatcher\n",
      "There Will Be Blood\n",
      "The Believer\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity = sklearn.metrics.pairwise.cosine_similarity(tfidf_new, tfidf).flatten()\n",
    "indices = np.argsort(-cosine_similarity)[:10]\n",
    "for idx in indices:\n",
    "    print(movies[idx].get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c42ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7113, 65108)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_new.shape\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d32b71",
   "metadata": {},
   "source": [
    "### Wrapping-up for a more user-friendly perspective\n",
    "\n",
    " - Were the movies correctly identified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "274e491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . The Lord of the Rings: The Two Towers\n",
      "2 . The Lord of the Rings: The Fellowship of the Ring\n",
      "3 . The Lord of the Rings: The Return of the King\n",
      "4 . What's the Worst That Could Happen?\n",
      "5 . St. Trinian's II: The Legend of Fritton's Gold\n",
      "6 . O Brother, Where Art Thou?\n",
      "7 . Without Evidence\n",
      "8 . Blonde Fist\n",
      "9 . All the Real Girls\n",
      "10 . Twin Peaks: Fire Walk with Me\n"
     ]
    }
   ],
   "source": [
    "## Example 1, trying to reach on the Lord of The Rings Saga\n",
    "\n",
    "# Place the intended plot in here\n",
    "new_plot = [\"A grupo of people tries to return a ring. Mordor does not approve\"]\n",
    "\n",
    "tfidf_new = trained_vectorizer.transform(new_plot) #vamos transformar os novos dados no modelo que acabámos de treinar\n",
    "\n",
    "cosine_similarity = sklearn.metrics.pairwise.cosine_similarity(tfidf_new, tfidf).flatten()\n",
    "indices = np.argsort(-cosine_similarity)[:10]\n",
    "for idx, movie_title in enumerate(indices):\n",
    "    print(idx+1,\".\", movies[movie_title].get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240833e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Harry Potter and the Deathly Hallows: Part I\n",
      "2 . Harry Potter and the Deathly Hallows: Part 1\n",
      "3 . Harry Potter and the Sorcerer's Stone\n",
      "4 . Harry Potter and the Philosopher's Stone\n",
      "5 . Harry Potter and the Prisoner of Azkaban\n",
      "6 . Harry Potter and the Order of the Phoenix\n",
      "7 . Harry Potter and the Chamber of Secrets\n",
      "8 . Village of the Damned\n",
      "9 . Magic Island (film)\n",
      "10 . Harry Potter and the Deathly Hallows: Part 2\n"
     ]
    }
   ],
   "source": [
    "## Example 2, trying to reach to the Harry Potter Saga\n",
    "\n",
    "# Place the intended plot in here\n",
    "new_plot = [\"Children go to magic school. Also, there's Hermione\"]\n",
    "\n",
    "tfidf_new = trained_vectorizer.transform(new_plot) #vamos transformar os novos dados no modelo que acabámos de treinar\n",
    "\n",
    "cosine_similarity = sklearn.metrics.pairwise.cosine_similarity(tfidf_new, tfidf).flatten()\n",
    "indices = np.argsort(-cosine_similarity)[:10]\n",
    "for idx, movie_title in enumerate(indices):\n",
    "    print(idx+1,\".\", movies[movie_title].get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc96da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . All Is Lost\n",
      "2 . Titanic\n",
      "3 . Under the Skin\n",
      "4 . Deep Rising\n",
      "5 . Trust\n",
      "6 . Gunmen\n",
      "7 . 47 Meters Down\n",
      "8 . The Road\n",
      "9 . Only for You\n",
      "10 . Paper Heart\n"
     ]
    }
   ],
   "source": [
    "## Example 3, trying to reach to Titanic\n",
    "\n",
    "# Place the intended plot in here\n",
    "new_plot = [\"A boat sinks on its first voyage. Romance between a man and a woman\"]\n",
    "\n",
    "tfidf_new = trained_vectorizer.transform(new_plot) #vamos transformar os novos dados no modelo que acabámos de treinar\n",
    "\n",
    "cosine_similarity = sklearn.metrics.pairwise.cosine_similarity(tfidf_new, tfidf).flatten()\n",
    "indices = np.argsort(-cosine_similarity)[:10]\n",
    "for idx, movie_title in enumerate(indices):\n",
    "    print(idx+1,\".\", movies[movie_title].get(\"title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ce62e",
   "metadata": {},
   "source": [
    "### Final comments:\n",
    "The used method is far from perfect and it is only identifying how many times a word or token appears out of all words or tokens based on their relative frequency on the database that was given. The more frequent or more specific a word is used the more probable is that that word will correctly identify a film. \n",
    "\n",
    "For example, searching by \"ring\" will not be as effective as using \"Mordor\" on identifying the LOTR saga.\n",
    "\n",
    "The same happens with the word \"magic\" or \"wand\" that by itself will not identify the Harry Potter movies saga, but by placing the word \"Hermione\" it will immediatly identify it correctly.\n",
    "\n",
    "On the last example, using a more general description of the film it's identified correctly the target movie on the Top 10 movies, although since it's not specific enough it won't be identifying the movie immediatly, but other key-expressions could be better used on this topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
